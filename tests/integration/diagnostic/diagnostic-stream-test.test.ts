
import { test, expect, describe } from 'bun:test'
import { ModelAdapterFactory } from '@services/modelAdapterFactory'
import { callGPT5ResponsesAPI } from '@services/openai'

const MOCK_SERVER_TEST_MODE = process.env.MOCK_SERVER_TEST_MODE === 'true'

const GPT5_CODEX_PROFILE = {
  name: 'gpt-5-codex',
  provider: 'openai',
  modelName: 'gpt-5-codex',
  baseURL: process.env.TEST_GPT5_BASE_URL || 'http://127.0.0.1:3000/openai',
  apiKey: process.env.TEST_GPT5_API_KEY || '',
  maxTokens: 8192,
  contextLength: 128000,
  reasoningEffort: 'high',
  isActive: true,
  createdAt: Date.now(),
}

describe('ðŸ” Diagnostic: Stream State Tracking', () => {
  if (!MOCK_SERVER_TEST_MODE) {
    test.skip('Track stream locked state through the entire pipeline (requires MOCK_SERVER_TEST_MODE=true)', () => {})
    test.skip('Compare streaming vs non-streaming responses (requires MOCK_SERVER_TEST_MODE=true)', () => {})
    return
  }

  test('Track stream locked state through the entire pipeline', async () => {
    console.log('\nðŸ” DIAGNOSTIC TEST: Stream State Tracking')
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')

    console.log('\nStep 1: Creating adapter...')
    const adapter = ModelAdapterFactory.createAdapter(GPT5_CODEX_PROFILE)
    console.log(`  âœ… Adapter: ${adapter.constructor.name}`)

    console.log('\nStep 2: Building request with streaming...')
    const unifiedParams = {
      messages: [{ role: 'user', content: 'Hello, write 3 words.' }],
      systemPrompt: ['You are a helpful assistant.'],
      tools: [],
      maxTokens: 50,
      stream: true,
      reasoningEffort: 'high' as const,
      temperature: 1,
      verbosity: 'high' as const,
    }
    console.log('  âœ… Unified params built with stream: true')

    console.log('\nStep 3: Creating request...')
    const request = adapter.createRequest(unifiedParams)
    console.log('  âœ… Request created')
    console.log(`  ðŸ“ Stream in request: ${request.stream}`)

    console.log('\nStep 4: Making API call (STREAMING)...')
    const response = await callGPT5ResponsesAPI(GPT5_CODEX_PROFILE, request)

    console.log('\nStep 5: Checking stream state BEFORE adapter...')
    console.log(`  ðŸ“Š Response status: ${response.status}`)
    console.log(`  ðŸ“Š Response ok: ${response.ok}`)
    console.log(`  ðŸ“Š Response type: ${response.type}`)
    console.log(`  ðŸ“Š Response body exists: ${!!response.body}`)
    console.log(
      `  ðŸ“Š Response body locked: ${response.body?.locked || 'N/A (not a ReadableStream)'}`,
    )

    if (response.body && typeof response.body.getReader === 'function') {
      console.log(`  âœ… Confirmed: Response.body is a ReadableStream`)

      console.log(`  ðŸ”’ Initial locked state: ${response.body.locked}`)

      if (response.body.locked) {
        console.log('\nâŒ CRITICAL ISSUE FOUND: Stream is already locked!')
        console.log(
          '   This means something consumed the stream BEFORE adapter.parseResponse()',
        )
        console.log('   Possible culprits:')
        console.log('   - Middleware/interceptor reading the response')
        console.log(
          '   - Debug logging calling response.json() or response.text()',
        )
        console.log('   - Error handler accessing the body')
        throw new Error(
          'Stream locked before adapter.parseResponse() - investigate what consumed it!',
        )
      }
    } else {
      console.log('  âš ï¸  WARNING: Response.body is NOT a ReadableStream')
      console.log('   This might be because:')
      console.log('   - The API returned a non-streaming response')
      console.log('   - The response was already consumed and converted')
    }

    console.log('\nStep 6: Parsing response with adapter...')
    let unifiedResponse
    try {
      unifiedResponse = await adapter.parseResponse(response)
      console.log('  âœ… Response parsed successfully')
    } catch (error) {
      console.log('  âŒ Error parsing response:')
      console.log(`   Message: ${error.message}`)
      console.log(`   Stack: ${error.stack}`)

      if (
        error.message.includes('locked') ||
        error.message.includes('reader')
      ) {
        console.log('\nðŸ’¡ ROOT CAUSE IDENTIFIED:')
        console.log(
          '   The stream was locked between API call and parseResponse()',
        )
        console.log(
          '   This is the exact bug causing empty content in the CLI!',
        )
      }

      throw error
    }

    console.log('\nStep 7: Validating result...')
    console.log(`  ðŸ“„ Response ID: ${unifiedResponse.id}`)
    console.log(
      `  ðŸ“„ Content type: ${Array.isArray(unifiedResponse.content) ? 'array' : typeof unifiedResponse.content}`,
    )
    console.log(
      `  ðŸ“„ Content length: ${Array.isArray(unifiedResponse.content) ? unifiedResponse.content.length : unifiedResponse.content?.length || 0}`,
    )

    let actualText = ''
    if (Array.isArray(unifiedResponse.content)) {
      actualText = unifiedResponse.content
        .filter(block => block.type === 'text')
        .map(block => block.text)
        .join('')
    } else if (typeof unifiedResponse.content === 'string') {
      actualText = unifiedResponse.content
    }

    console.log(`  ðŸ“„ Actual text: "${actualText}"`)
    console.log(`  ðŸ”§ Tool calls: ${unifiedResponse.toolCalls.length}`)

    expect(unifiedResponse).toBeDefined()
    expect(unifiedResponse.content).toBeDefined()
    expect(Array.isArray(unifiedResponse.content)).toBe(true)

    if (actualText.length === 0) {
      console.log('\nâŒ CONFIRMED BUG: Content is empty!')
      console.log('   This matches the CLI behavior.')
      console.log('   The stream was either:')
      console.log('   1. Already consumed/locked before adapter could read it')
      console.log('   2. Never had data to begin with (API returned empty)')
      console.log('   3. SSE parsing failed (wrong event structure)')
    } else {
      console.log(
        '\nâœ… Content received! This test would pass if the bug is fixed.',
      )
    }

    console.log('\nðŸ“Š DIAGNOSTIC SUMMARY:')
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    console.log(`  Response OK: ${response.ok}`)
    console.log(`  Body Type: ${typeof response.body}`)
    console.log(`  Body Locked: ${response.body?.locked || 'N/A'}`)
    console.log(`  Content Length: ${actualText.length}`)
    console.log(`  Test Result: ${actualText.length > 0 ? 'PASS' : 'FAIL'}`)
  })

  test('Compare streaming vs non-streaming responses', async () => {
    console.log('\nðŸ” COMPARISON TEST: Stream vs Non-Stream')
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')

    const adapter = ModelAdapterFactory.createAdapter(GPT5_CODEX_PROFILE)

    console.log('\nðŸ“¡ Testing with stream: true...')
    const streamingParams = {
      messages: [{ role: 'user', content: 'Say "STREAM".' }],
      systemPrompt: ['You are a helpful assistant.'],
      tools: [],
      maxTokens: 10,
      stream: true,
      reasoningEffort: 'high' as const,
      temperature: 1,
      verbosity: 'high' as const,
    }

    const streamingRequest = adapter.createRequest(streamingParams)
    const streamingResponse = await callGPT5ResponsesAPI(
      GPT5_CODEX_PROFILE,
      streamingRequest,
    )
    const streamingResult = await adapter.parseResponse(streamingResponse)

    const streamingText = Array.isArray(streamingResult.content)
      ? streamingResult.content
          .filter(b => b.type === 'text')
          .map(b => b.text)
          .join('')
      : streamingResult.content

    console.log(`  Stream forced: ${streamingRequest.stream}`)
    console.log(`  Body type: ${typeof streamingResponse.body}`)
    console.log(`  Content: "${streamingText}"`)

    console.log('\nðŸ“¡ Testing with stream: false...')
    const nonStreamingParams = {
      ...streamingParams,
      stream: false,
    }

    const nonStreamingRequest = adapter.createRequest(nonStreamingParams)
    const nonStreamingResponse = await callGPT5ResponsesAPI(
      GPT5_CODEX_PROFILE,
      nonStreamingRequest,
    )
    const nonStreamingResult = await adapter.parseResponse(nonStreamingResponse)

    const nonStreamingText = Array.isArray(nonStreamingResult.content)
      ? nonStreamingResult.content
          .filter(b => b.type === 'text')
          .map(b => b.text)
          .join('')
      : nonStreamingResult.content

    console.log(`  Stream requested: ${nonStreamingParams.stream}`)
    console.log(`  Stream forced: ${nonStreamingRequest.stream}`)
    console.log(`  Body type: ${typeof nonStreamingResponse.body}`)
    console.log(`  Content: "${nonStreamingText}"`)

    console.log('\nðŸ“Š COMPARISON:')
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    console.log(`  Streaming content length: ${streamingText.length}`)
    console.log(`  Non-streaming content length: ${nonStreamingText.length}`)
    console.log(
      `  Difference: ${nonStreamingText.length - streamingText.length}`,
    )

    if (streamingText.length === 0 && nonStreamingText.length > 0) {
      console.log('\nðŸ’¡ KEY FINDING:')
      console.log(
        '   The adapter forces stream: true, but returns empty content!',
      )
      console.log('   This suggests the SSE parsing is failing silently.')
    }
  })
})
